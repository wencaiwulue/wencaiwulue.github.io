temperature
用于控制模型输出的结果的随机性，这个值越大随机性越大。一般我们多次输入相同的prompt之后，模型的每次输出都不一样。
设置为 0，对每个prompt都生成固定的输出
较低的值，输出更集中，更有确定性
较高的值，输出更随机（更有创意 ）

top-k: 从 tokens 里选择 k 个作为候选，然后根据它们的 likelihood scores 来采样
设置越大，生成的内容可能性越大；
设置越小，生成的内容越固定；
设置为1时，和 greedy decoding 效果一样。
greedy decoding: 总是选择最高分的 token，有用但是有些弊端，好处是简单，坏处是容易生成循环、重复的内容

top-p: 候选词列表是动态的，从 tokens 里按百分比选择候选词
设置越大，生成的内容可能性越大；
设置越小，生成的内容越固定；